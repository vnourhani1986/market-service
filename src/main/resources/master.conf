akka {
  loglevel = INFO
  stdout-loglevel = INFO
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logger-startup-timeout = 30s
  default-dispatcher {
    fork-join-executor {
      parallelism-min = 8
    }
  }
  test {
    timefactor = 1
  }
  http {
    server {
      server-header = "myticket.snapptrip.com REST API"
      //request-timeout = 30s
    }
  }
}


db {
  url = "jdbc:postgresql://db-market/webeng"
  user = "b2c"
  password = "E9WAk?C#>GE<9Ge=w"
  poolName = "master"
  numThreads = 10
  connectionTimeout = 10s
  validationTimeout = 10s
  properties {
    sslfactory = org.postgresql.ssl.NonValidatingFactory
  }
}

slick-postgres {

  profile = "slick.jdbc.PostgresProfile$"

  db {
    dataSourceClass = "slick.jdbc.DriverDataSource"
    properties = {
      driver = "org.postgresql.Driver"
      url = "jdbc:postgresql://db-market/webeng?ApplicationName=Market&sslfactory=org.postgresql.ssl.NonValidatingFactory"
      user = "b2c"
      password = "E9WAk?C#>GE<9Ge=w"
    }

  }
}

http {
  host = "0.0.0.0"
  port = 9000
}

https {
  host = "0.0.0.0"
  port = 9000
}

snapptrip-auth {
  api-base-url = "auth.core"
  login-url = "/v1/auth"
  auth-url = "/v1/auth"
  port = 9000
}

web-engage {
  host = "api.webengage.com"
  api-base-url = "/v1/accounts/"
  event-url = "/events"
  user-url = "/users"
  opengdpr-requests-url = "/opengdpr_requests"
  license-code = "11b5650c0"
  api-key = "Bearer 9f86b2a7-1497-4adc-856b-df4211abb0cc"
  token = "c2747d3b-e92c-4015-be00-29bb9e477f4b"
  time-offset = "+0430"
}

notification {
  host = "notification-azure.core"
  api-base-url = ""
  sms-url = "/v2/notifications"
  email-url = "/v2/emails"
  client = "ptp-b2c"
}

sentry {
  dns: "http://05fd30058bef4c148c747afdba90c832@sentry.snapptrip.com/25"
  environment: "production"
}

// This is used when calculating datetimes, durations, intervals, and FlightModule.now().
timezone = "Asia/Tehran"

redis {
  ip: "192.168.1.3"
  db: 5
  connectionTimeout: 30s
}

// ***************************** kafka config ******************************** //
kafka {
  bootstrap.servers = "192.168.1.55:9094"
  topic = "test"
}

# Properties for akka.kafka.ProducerSettings can be
# defined in this section or a configuration section with
# the same layout.
akka.kafka.producer {
  # Tuning parameter of how many sends that can run in parallel.
  parallelism = 100

  # How long to wait for `KafkaProducer.close`
  close-timeout = 60s

  # Fully qualified config path which holds the dispatcher configuration
  # to be used by the producer stages. Some blocking may occur.
  # When this value is empty, the dispatcher configured for the stream
  # will be used.
  use-dispatcher = "akka.kafka.default-dispatcher"

  # The time interval to commit a transaction when using the `Transactional.sink` or `Transactional.flow`
  eos-commit-interval = 100ms

  # Properties defined by org.apache.kafka.clients.producer.ProducerConfig
  # can be defined in this configuration section.
  kafka-clients {
  }
}

# // #consumer-settings
# Properties for akka.kafka.ConsumerSettings can be
# defined in this section or a configuration section with
# the same layout.
akka.kafka.consumer {
  # Tuning property of scheduled polls.
  poll-interval = 50ms

  # Tuning property of the `KafkaConsumer.poll` parameter.
  # Note that non-zero value means that the thread that
  # is executing the stage will be blocked.
  poll-timeout = 50ms

  # The stage will await outstanding offset commit requests before
  # shutting down, but if that takes longer than this timeout it will
  # stop forcefully.
  stop-timeout = 30s

  # How long to wait for `KafkaConsumer.close`
  close-timeout = 20s

  # If offset commit requests are not completed within this timeout
  # the returned Future is completed `CommitTimeoutException`.
  commit-timeout = 15s

  # If commits take longer than this time a warning is logged
  commit-time-warning = 1s

  # If for any reason `KafkaConsumer.poll` blocks for longer than the configured
  # poll-timeout then it is forcefully woken up with `KafkaConsumer.wakeup`.
  # See https://kafka.apache.org/10/javadoc/org/apache/kafka/clients/consumer/KafkaConsumer.html#wakeup--
  # The KafkaConsumerActor will throw
  # `org.apache.kafka.common.errors.WakeupException` which will be ignored
  # until `max-wakeups` limit gets exceeded.
  wakeup-timeout = 3s

  # After exceeding maxinum wakeups the consumer will stop and the stage and fail.
  # Setting it to 0 will let it ignore the wakeups and try to get the polling done forever.
  max-wakeups = 10

  # If set to a finite duration, the consumer will re-send the last committed offsets periodically
  # for all assigned partitions. See https://issues.apache.org/jira/browse/KAFKA-4682.
  commit-refresh-interval = infinite

  # If enabled, log stack traces before waking up the KafkaConsumer to give
  # some indication why the KafkaConsumer is not honouring the `poll-timeout`
  wakeup-debug = true

  # Fully qualified config path which holds the dispatcher configuration
  # to be used by the KafkaConsumerActor. Some blocking may occur.
  use-dispatcher = "akka.kafka.default-dispatcher"

  # Properties defined by org.apache.kafka.clients.consumer.ConsumerConfig
  # can be defined in this configuration section.
  kafka-clients {
    # Disable auto-commit by default
    enable.auto.commit = false

  }

  # Time to wait for pending requests when a partition is closed
  wait-close-partition = 500ms
}
# // #consumer-settings

# The dispatcher that will be used by default by consumer and
# producer stages.
akka.kafka.default-dispatcher {
  type = "Dispatcher"
  executor = "thread-pool-executor"

  thread-pool-executor {
    fixed-pool-size = 16
  }
}

// ********************************** end kafka config *****************************************